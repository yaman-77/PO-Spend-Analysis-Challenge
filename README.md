# ğŸ›  Procurement Item Classification â€” A Prototype Journey

## ğŸ“Œ Project Overview
This repository documents a **prototype project** digging deep into the **spendings of line items in Purchase Orders**.  
To achieve this, we tested classifying messy procurement items into meaningful categories using both **manual taxonomy** and **embedding-based approaches**.  

The dataset was messy, containing **bilingual item names (Arabic & English)** with inconsistent formats, codes, specs, and vendor references.

The journey focused on answering one key question:  

> **Can we bring structure and insights to unstructured procurement text data with limited resources?**

---

## ğŸš€ Problem Statement
Procurement spend analysis often relies on structured item categories. In reality, item descriptions are messy:

- Written in both Arabic and English  
- Mixed with units, codes, and specs (`"12 Ù…Ù…"`, `"g60"`, `"1220 2440"`)  
- Vendors and brands inserted into the text (`Ø³Ø§Ø¨Ùƒ`, `Al-Suwaidi`)  

Without clean categories, organizations canâ€™t answer basic strategic questions such as:
- Which categories drive the majority of spend?  
- Where can we negotiate better with suppliers?  
- Which classes dominate in quantity?  

---

## ğŸ§­ Our Approach (Step by Step)

### ğŸ”¹ Exploration
- Started with **word frequency analysis (unigrams)**.  
- Found that most frequent tokens were **units and codes** (e.g., `mm`, `Ù…Ù…`, `x`, `f`).  
- **Insight:** raw word counts werenâ€™t enough.  

### ğŸ”¹ Bi-gram Analysis
- Extracted **two-word combinations** (e.g., `Ø­Ø¯ÙŠØ¯ ØªØ³Ù„ÙŠØ­`, `steel bar`, `Ù…Ø§Ø³ÙˆØ±Ø© Ø­Ø¯ÙŠØ¯`).  
- Surfaced **product-level signals**: rebar, sheets, pipes, cables.  
- Still noisy, but better than unigrams.  

### ğŸ”¹ Manual Classification
- Created initial keyword-based classes:
  - Rebar & Steel Bars  
  - Steel Sheets / Plates  
  - Pipes & Tubes  
  - Other / Specs / Unclassified  
- Mined **â€œOtherâ€** â†’ discovered new families: **Electrical, Concrete Panels, Fasteners, Coatings**.  
- Expanded taxonomy to **7 categories**.  

### ğŸ”¹ Embedding-based Classification
- Used **`sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`**.  
- Created **prototypes** for each class using bilingual prompts.  
- Encoded all items â†’ matched to closest class by **cosine similarity**.  
- Supported **multi-label classification** when an item spanned categories.  

### ğŸ”¹ Visualization & Dashboard
Built a basic dashboard (matplotlib/seaborn) to show:
- Total spend and quantities  
- Top POs by spend/qty  
- Top classes by spend/qty  
- % share of each category  

Enabled quick insights like:  
> *â€œ2 classes account for 50% of spend â€” these are strategic categories.â€*  

---

## âš ï¸ Limitations
Itâ€™s evident this is not the optimal way of approaching the problem, but a strong prototype:  

- Heavy reliance on **item names only**; ignored supplier codes, units, or material groups.  
- Embedding thresholds and keyword lists were **heuristic**, not tuned with labeled data.  
- Category taxonomy was **manually designed**, so may miss edge cases.  
- Noise from specs and codes still affects classification accuracy.  

---

## ğŸ”® Future Recommendations
- Incorporate **structured fields** (supplier, material codes, units) to complement text.  
- Build a **labeled dataset** â†’ train supervised models, validate properly.  
- Expand taxonomy with **domain experts** to ensure coverage.  
- Deploy in an **interactive dashboard** where users can correct classifications â†’ create feedback loops.  
- Explore **semi-supervised clustering** with embeddings for continuous discovery of new categories.  

---

## ğŸ“Š Example Outputs
- **Spend concentration**: showed that 2 categories alone made up ~50% of spend.  
  - **Insight:** treat them as *strategic categories* in sourcing and risk planning.  
- **Quantity analysis**: highlighted classes that drive procurement in volume but not spend.  
- Provided an early look at how **text + embeddings** can unlock value in messy ERP data.  

---

## ğŸ›  Tech Stack
- **Python 3.9**  
- **Libraries**: pandas, numpy, matplotlib, seaborn, scikit-learn, sentence-transformers, openpyxl  
- **Environment**: managed with conda (`environment.yml` included)  

---

## ğŸ“‚ Repository Structure
```plaintext
â”œâ”€â”€ notebooks/         # Jupyter notebooks with analysis & experiments
â”œâ”€â”€ src/               # Helper scripts for classification & embeddings
â”œâ”€â”€ environment.yml    # Conda environment for reproducibility
â”œâ”€â”€ README.md          # This file
```


ğŸ™Œ Closing Note

This prototype demonstrates that even with messy, bilingual procurement data, itâ€™s possible to create a structured spend classification pipeline. While not production-ready, it showcases the potential if more time and resources were invested.
